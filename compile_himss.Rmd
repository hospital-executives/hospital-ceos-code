---
title: "compile_himss"
output: html_document
date: "2024-04-02"
params:
  code_dir: "None" # CHANGED FROM MICHELLE
---

### Script Overview
Re-build Maggie's Stata code to clean and compile each year's HIMSS survey. Focus on 2005 - 2017. Recreate healthcare_execs_0517, but in R.

## Set-up

```{r manual setup user entry req, include=FALSE}
#User entry required!

#clear environment
rm(list = setdiff(ls(), c("params"))) # CHANGED FROM MICHELLES

# *** IMPORTING RAW HIMS ***
# Define the range of years to import
year_range <- 2005:2017 

# Specify the prefixes of files you want to import
file_prefixes <- c("Contact_", "HAEntityContact_","HAEntity_", "ContactType_","ContactSource_")

# *** IMPORTING AHA DATA ***
file_name_aha <- c("aha-raw-2000-20.dta")

columns_to_keep <- c( 
  "ID", 
  "YEAR", 
  "MNAME", 
  "HOSPN", 
  "mcrnum", 
  "CBSANAME", 
  "HRRNAME", 
  "HSANAME", 
  "MADMIN", 
  "SYSID", 
  "SYSNAME", 
  "CNTRL", 
  "SERV", 
  "HOSPBD", 
  "BDTOT", 
  "ADMTOT", 
  "IPDTOT", 
  "MCRDC", 
  "MCRIPD", 
  "MCDDC", 
  "MCDIPD", 
  "BIRTHS", 
  "FTEMD", 
  "FTERN", 
  "FTE",
  "LAT",
  "LONG"
   ) # Replace with your desired column names

# *** IMPORTING AHA<>MCR CROSSWALK ***
file_name_aha_mcr_xwalk <- c("hospital_ownership.dta")

```


```{r auto setup, include=FALSE}
# NO manual entry required. This automatically loads necessary libraries and detects file paths. 
knitr::opts_chunk$set(echo = TRUE)

# Source the configuration script
# Check if rstudioapi is installed and install if necessary
if (!requireNamespace("rstudioapi", quietly = TRUE)) {
  install.packages("rstudioapi")
}

library(rstudioapi)

# Detect the path to the current script's directory dynamically
# CHANGED FROM MICHELLE'S CODE
if (rstudioapi::isAvailable()) {
  script_directory <- dirname(rstudioapi::getActiveDocumentContext()$path)
} else {
  # Provide a fallback path or set a default
  script_directory <- params$code_dir
}

# Construct the path to the config.R file
config_path <- file.path(script_directory, "config.R")

# Source the config file dynamically
source(config_path)

#Now all necessary libraries are loaded, and file paths are set

#clean up
rm(script_directory, config_path)
```

## Pull in raw, HIMSS files

```{r import all original himss}
#a separate bash script extracted the original Access DB tables as CSVs
#these are loaded to DropBox, we only want a subset (defined in file_prefixes)

folders <- list.dirs(path = raw_data, full.names = TRUE, recursive = FALSE)

# Loop through each file prefix
for (prefix in file_prefixes) {
  temp_dfs <- list()  # Temporary list to store dataframes for this prefix
  
  # Loop through each year
  for (year in year_range) {
    file_path <- paste0(prefix, year, ".csv")  # Construct the file name
    full_path <- file.path(raw_data, as.character(year), file_path)  # Full file path
    
  #Check if the file exists, import
    if (file.exists(full_path)) {
       #Importing all as character. 
       #There are some differences within year 
       #(e.g. most phone numbers will be ##########, but some will be ###-###-####. 
       #Without converting to character, we see data loss when the mismatched value is not imported 
       #e.g. ###-###-#### would be NA
      df <- read_csv(full_path, show_col_types = FALSE, col_types = cols(.default = col_character())) %>%
        # Add a year value and and make all vars lowercase
        mutate(year = year) %>%  # Add the year as a new column
        rename_with(tolower)

      # In some years the same fields data storage type changed. Dynamically adjust data types for combination: Convert numeric and logical columns to character.
      # df <- df %>%
      #   mutate(across(where(is.numeric), ~if_else(is.na(.), as.character(.), as.character(.)))) %>%
      #   mutate(across(where(is.logical), as.character))

      temp_dfs[[length(temp_dfs) + 1]] <- df
    }
  }
  
  # Combine all dataframes, now with consistent data types
  combined_df <- bind_rows(temp_dfs)
  
  # Dynamically assign the combined dataframe to a variable in the global environment
  var_name <- tolower(str_remove(prefix, "_$"))
  assign(var_name, combined_df, envir = .GlobalEnv)
}

# Clean up temporary variables
rm(list = c("combined_df", "df", "temp_dfs","var_name","year", "year_range"))
```

```{r calculate original import misses}
#In original loop, mismatched col values (within a given year) were being dropped. this section calculates the total impact of that.

# Define the range of years to import
year_range <- 2005:2017 

# Specify the prefixes of files you want to import
file_prefixes <- c("Contact_", "HAEntityContact_", "HAEntity_", "ContactType_", "ContactSource_")

# Initialize a list to store all parsing issues
all_parsing_issues <- list()
# Initialize a variable to count the total number of issues
total_issues_count <- 0

# Loop through each year and file prefix to import files and check for parsing issues
for (year in year_range) {
  for (prefix in file_prefixes) {
    file_path <- paste0(prefix, year, ".csv")  # Construct the file name
    full_path <- file.path(raw_data, as.character(year), file_path)  # Full file path

    # Check if the file exists, import it, and collect parsing issues
    if (file.exists(full_path)) {
      # Read the data
      test_df <- read_csv(full_path, show_col_types = TRUE)
      
      # Check for parsing problems
      parsing_issues <- problems(test_df)
      issue_count <- nrow(parsing_issues)  # Count the number of issues
      if (issue_count > 0) {
        # Store parsing issues in the list with the file path as the name
        all_parsing_issues[[paste0(prefix, year)]] <- parsing_issues
        # Add to total issues count
        total_issues_count <- total_issues_count + issue_count
      }
    } else {
      message(paste("File does not exist at:", full_path))
    }
  }
}

# Function to print all parsing issues
print_all_parsing_issues <- function(all_issues) {
  if (length(all_issues) > 0) {
    for (name in names(all_issues)) {
      issue_count <- nrow(all_issues[[name]])
      cat("\nParsing issues for file:", name, " - Total issues:", issue_count, "\n")
      print(all_issues[[name]])
    }
    cat("\nTotal number of parsing issues across all files:", total_issues_count, "\n")
  } else {
    message("No parsing issues detected for any files.")
  }
}

# Print all parsing issues for review
print_all_parsing_issues(all_parsing_issues)

```


